{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T17:59:34.129611Z",
     "iopub.status.busy": "2025-12-29T17:59:34.129117Z",
     "iopub.status.idle": "2025-12-29T17:59:35.173958Z",
     "shell.execute_reply": "2025-12-29T17:59:35.173143Z",
     "shell.execute_reply.started": "2025-12-29T17:59:34.129587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DUALFormer'...\n",
      "remote: Enumerating objects: 32, done.\u001b[K\n",
      "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
      "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
      "remote: Total 32 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (32/32), 1.79 MiB | 7.82 MiB/s, done.\n",
      "Resolving deltas: 100% (7/7), done.\n",
      "/kaggle/working/DUALFormer\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/JiamingZhuo/DUALFormer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T01:59:28.076785Z",
     "iopub.status.busy": "2026-01-06T01:59:28.076121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0+cu126\n",
      "CUDA: 12.6\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Kiểm tra phiên bản PyTorch và CUDA đang chạy trên Kaggle\n",
    "import torch\n",
    "import subprocess\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "\n",
    "# Cài đặt PyTorch Geometric và các thư viện phụ trợ (Scatter, Sparse)\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T01:59:10.269383Z",
     "iopub.status.busy": "2026-01-06T01:59:10.268635Z",
     "iopub.status.idle": "2026-01-06T01:59:10.386511Z",
     "shell.execute_reply": "2026-01-06T01:59:10.385864Z",
     "shell.execute_reply.started": "2026-01-06T01:59:10.269349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/DUALFormer\n"
     ]
    }
   ],
   "source": [
    "# Di chuyển vào thư mục dự án\n",
    "%cd DUALFormer\n",
    "\n",
    "# Tạo thư mục chứa kết quả (để tránh lỗi khi code cố gắng ghi file csv)\n",
    "!mkdir -p results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T02:37:05.126708Z",
     "iopub.status.busy": "2026-01-06T02:37:05.126365Z",
     "iopub.status.idle": "2026-01-06T02:37:05.132681Z",
     "shell.execute_reply": "2026-01-06T02:37:05.131940Z",
     "shell.execute_reply.started": "2026-01-06T02:37:05.126673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "util_content = \"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.datasets import Planetoid, WebKB, Actor, Amazon, WikiCS, WikipediaNetwork, Coauthor\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse, to_torch_coo_tensor\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def DataLoader(name):\n",
    "    name = name.lower()\n",
    "    root_path = 'datasets/'\n",
    "    if name in ['cora', 'citeseer', 'pubmed']:\n",
    "        # Dùng split='public' thay vì 'random' để khớp với paper\n",
    "        dataset = Planetoid(root_path, name, split='public', transform=T.NormalizeFeatures())\n",
    "    elif name in ['computers', 'photo']:\n",
    "        dataset = Amazon(root_path, name, T.NormalizeFeatures())\n",
    "    elif name in ['cs', 'physics']:\n",
    "        dataset = Coauthor(root_path, name, T.NormalizeFeatures())\n",
    "    elif name in ['chameleon', 'squirrel']:\n",
    "        preProcDs = WikipediaNetwork(root=root_path, name=name, geom_gcn_preprocess=True, transform=T.NormalizeFeatures())\n",
    "        dataset = WikipediaNetwork(root=root_path, name=name, geom_gcn_preprocess=True, transform=T.NormalizeFeatures())\n",
    "        data = dataset[0]\n",
    "        data.edge_index = preProcDs[0].edge_index\n",
    "        dataset.data = data\n",
    "        return dataset\n",
    "    elif name in ['film']:\n",
    "        dataset = Actor(root=root_path+'/Actor', transform=T.NormalizeFeatures())\n",
    "        dataset.name = name\n",
    "    elif name in ['texas', 'cornell', 'wisconsin']:\n",
    "        dataset = WebKB(root=root_path, name=name, transform=T.NormalizeFeatures())\n",
    "    elif name in ['wikics']:\n",
    "        dataset = WikiCS(root=root_path+'/WikiCS', transform=T.NormalizeFeatures())\n",
    "    else:\n",
    "        raise ValueError(f'dataset {name} not supported in dataloader')\n",
    "    return dataset\n",
    "\n",
    "def dataset_split(data, run_id):\n",
    "    if data.name in ['wikics', 'computers', 'photo', 'physics']:\n",
    "        return get_split(num_samples=data.num_nodes, train_ratio=0.1, test_ratio=0.8)\n",
    "    elif data.name in ['cora', 'citeseer', 'pubmed']:\n",
    "        return get_public_split(data)\n",
    "\n",
    "def get_public_split(data):\n",
    "    return {\n",
    "        'train': torch.where(data.train_mask)[0],\n",
    "        'valid': torch.where(data.val_mask)[0],\n",
    "        'test': torch.where(data.test_mask)[0]\n",
    "    }\n",
    "\n",
    "def get_split(num_samples: int, train_ratio: float = 0.1, test_ratio: float = 0.1):\n",
    "    train_size = int(num_samples * train_ratio)\n",
    "    test_size = int(num_samples * test_ratio)\n",
    "    indices = torch.randperm(num_samples)\n",
    "    return {\n",
    "        'train': indices[:train_size],\n",
    "        'test': indices[train_size: test_size + train_size],\n",
    "        'valid': indices[test_size + train_size:]\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "with open('util.py', 'w') as f:\n",
    "    f.write(util_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T02:37:05.134003Z",
     "iopub.status.busy": "2026-01-06T02:37:05.133799Z",
     "iopub.status.idle": "2026-01-06T02:37:05.267138Z",
     "shell.execute_reply": "2026-01-06T02:37:05.266462Z",
     "shell.execute_reply.started": "2026-01-06T02:37:05.133983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import random\n",
      "import numpy as np\n",
      "import torch\n",
      "import os\n",
      "from torch_geometric.datasets import Planetoid, WebKB, Actor, Amazon, WikiCS, WikipediaNetwork, Coauthor\n",
      "import torch_geometric.transforms as T\n",
      "from torch_geometric.utils import to_dense_adj, dense_to_sparse, to_torch_coo_tensor\n",
      "\n",
      "def set_seed(seed):\n",
      "    random.seed(seed)\n",
      "    np.random.seed(seed)\n",
      "    torch.manual_seed(seed)\n",
      "    torch.cuda.manual_seed(seed)\n",
      "    torch.cuda.manual_seed_all(seed)\n",
      "    torch.backends.cudnn.deterministic = True\n",
      "    torch.backends.cudnn.benchmark = False\n",
      "\n",
      "def DataLoader(name):\n",
      "    name = name.lower()\n",
      "    root_path = 'datasets/'\n",
      "    if name in ['cora', 'citeseer', 'pubmed']:\n",
      "        # Dùng split='public' thay vì 'random' để khớp với paper\n",
      "        dataset = Planetoid(root_path, name, split='public', transform=T.NormalizeFeatures())\n",
      "    elif name in ['computers', 'photo']:\n",
      "        dataset = Amazon(root_path, name, T.NormalizeFeatures())\n",
      "    elif name in ['cs', 'physics']:\n",
      "        dataset = Coauthor(root_path, name, T.NormalizeFeatures())\n",
      "    elif name in ['chameleon', 'squirrel']:\n",
      "        preProcDs = WikipediaNetwork(root=root_path, name=name, geom_gcn_preprocess=True, transform=T.NormalizeFeatures())\n",
      "        dataset = WikipediaNetwork(root=root_path, name=name, geom_gcn_preprocess=True, transform=T.NormalizeFeatures())\n",
      "        data = dataset[0]\n",
      "        data.edge_index = preProcDs[0].edge_index\n",
      "        dataset.data = data\n",
      "        return dataset\n",
      "    elif name in ['film']:\n",
      "        dataset = Actor(root=root_path+'/Actor', transform=T.NormalizeFeatures())\n",
      "        dataset.name = name\n",
      "    elif name in ['texas', 'cornell', 'wisconsin']:\n",
      "        dataset = WebKB(root=root_path, name=name, transform=T.NormalizeFeatures())\n",
      "    elif name in ['wikics']:\n",
      "        dataset = WikiCS(root=root_path+'/WikiCS', transform=T.NormalizeFeatures())\n",
      "    else:\n",
      "        raise ValueError(f'dataset {name} not supported in dataloader')\n",
      "    return dataset\n",
      "\n",
      "def dataset_split(data, run_id):\n",
      "    if data.name in ['wikics', 'computers', 'photo', 'physics']:\n",
      "        return get_split(num_samples=data.num_nodes, train_ratio=0.1, test_ratio=0.8)\n",
      "    elif data.name in ['cora', 'citeseer', 'pubmed']:\n",
      "        return get_public_split(data)\n",
      "\n",
      "def get_public_split(data):\n",
      "    return {\n",
      "        'train': torch.where(data.train_mask)[0],\n",
      "        'valid': torch.where(data.val_mask)[0],\n",
      "        'test': torch.where(data.test_mask)[0]\n",
      "    }\n",
      "\n",
      "def get_split(num_samples: int, train_ratio: float = 0.1, test_ratio: float = 0.1):\n",
      "    train_size = int(num_samples * train_ratio)\n",
      "    test_size = int(num_samples * test_ratio)\n",
      "    indices = torch.randperm(num_samples)\n",
      "    return {\n",
      "        'train': indices[:train_size],\n",
      "        'test': indices[train_size: test_size + train_size],\n",
      "        'valid': indices[test_size + train_size:]\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "!cat util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T02:37:05.268948Z",
     "iopub.status.busy": "2026-01-06T02:37:05.268714Z",
     "iopub.status.idle": "2026-01-06T02:45:29.495233Z",
     "shell.execute_reply": "2026-01-06T02:45:29.494420Z",
     "shell.execute_reply.started": "2026-01-06T02:37:05.268924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu Grid Search trên 18 tổ hợp...\n",
      "\n",
      "--- Đang thử: WD=0.001, Dropout=0.1, Heads=2 ---\n",
      ">> Kết quả trung bình: 80.2%\n",
      "\n",
      "--- Đang thử: WD=0.001, Dropout=0.1, Heads=4 ---\n",
      ">> Kết quả trung bình: 80.8%\n",
      "\n",
      "--- Đang thử: WD=0.001, Dropout=0.3, Heads=2 ---\n",
      ">> Kết quả trung bình: 81.5%\n",
      "\n",
      "--- Đang thử: WD=0.001, Dropout=0.3, Heads=4 ---\n",
      ">> Kết quả trung bình: 82.2%\n",
      "\n",
      "--- Đang thử: WD=0.001, Dropout=0.5, Heads=2 ---\n",
      ">> Kết quả trung bình: 82.84%\n",
      "\n",
      "--- Đang thử: WD=0.001, Dropout=0.5, Heads=4 ---\n",
      ">> Kết quả trung bình: 82.24%\n",
      "\n",
      "--- Đang thử: WD=0.0001, Dropout=0.1, Heads=2 ---\n",
      ">> Kết quả trung bình: 80.4%\n",
      "\n",
      "--- Đang thử: WD=0.0001, Dropout=0.1, Heads=4 ---\n",
      ">> Kết quả trung bình: 81.06%\n",
      "\n",
      "--- Đang thử: WD=0.0001, Dropout=0.3, Heads=2 ---\n",
      ">> Kết quả trung bình: 81.3%\n",
      "\n",
      "--- Đang thử: WD=0.0001, Dropout=0.3, Heads=4 ---\n",
      ">> Kết quả trung bình: 81.96%\n",
      "\n",
      "--- Đang thử: WD=0.0001, Dropout=0.5, Heads=2 ---\n",
      ">> Kết quả trung bình: 82.26%\n",
      "\n",
      "--- Đang thử: WD=0.0001, Dropout=0.5, Heads=4 ---\n",
      ">> Kết quả trung bình: 83.4%\n",
      "\n",
      "--- Đang thử: WD=1e-05, Dropout=0.1, Heads=2 ---\n",
      ">> Kết quả trung bình: 80.86%\n",
      "\n",
      "--- Đang thử: WD=1e-05, Dropout=0.1, Heads=4 ---\n",
      ">> Kết quả trung bình: 80.74%\n",
      "\n",
      "--- Đang thử: WD=1e-05, Dropout=0.3, Heads=2 ---\n",
      ">> Kết quả trung bình: 81.4%\n",
      "\n",
      "--- Đang thử: WD=1e-05, Dropout=0.3, Heads=4 ---\n",
      ">> Kết quả trung bình: 81.68%\n",
      "\n",
      "--- Đang thử: WD=1e-05, Dropout=0.5, Heads=2 ---\n",
      ">> Kết quả trung bình: 82.32%\n",
      "\n",
      "--- Đang thử: WD=1e-05, Dropout=0.5, Heads=4 ---\n",
      ">> Kết quả trung bình: 83.08%\n",
      "\n",
      "==================================================\n",
      "KẾT QUẢ CAO NHẤT: 83.4%\n",
      "Lệnh chạy bộ tham số này:\n",
      "python train.py --dataset cora --num_sa 3 --num_gnns 2 --hidden 256 --alpha 0.1 --lr 0.001 --lr_sa 0.001 --weight_decay 0.0001 --weight_decay_sa 0.0001 --dropout 0.5 --dropout_sa 0.5 --num_heads 4 --epochs 300 --runs 5 --patience 50 --runs 10\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Chạy Grid Search để tìm bộ tham số tốt nhất trên dataset Cora\n",
    "# 1. Các tham số cố định chính xác theo Table 5 trong paper cho dataset Cora\n",
    "fixed_params = {\n",
    "    \"dataset\": \"cora\",\n",
    "    \"num_sa\": \"3\",\n",
    "    \"num_gnns\": \"2\",\n",
    "    \"hidden\": \"256\",\n",
    "    \"alpha\": \"0.1\",\n",
    "    \"lr\": \"0.001\",\n",
    "    \"lr_sa\": \"0.001\",\n",
    "    \"epochs\": \"300\",\n",
    "    \"patience\": \"50\",\n",
    "    \"runs\": \"5\"  # Tìm nhanh tổ hợp tốt nhất bằng cách chạy 5 lần\n",
    "}\n",
    "\n",
    "# 2. Dải tham số cần tìm kiếm (Grid Search) theo Section D.3\n",
    "search_space = {\n",
    "    \"wd\": [1e-3, 1e-4, 1e-5],\n",
    "    \"dropout\": [0.1, 0.3, 0.5],\n",
    "    \"heads\": [2, 4]\n",
    "}\n",
    "\n",
    "# Tạo danh sách các tổ hợp \n",
    "keys, values = zip(*search_space.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "best_acc = 0\n",
    "best_config = \"\"\n",
    "\n",
    "print(f\"Bắt đầu Grid Search trên {len(combinations)} tổ hợp...\")\n",
    "\n",
    "for config in combinations:\n",
    "    print(f\"\\n--- Đang thử: WD={config['wd']}, Dropout={config['dropout']}, Heads={config['heads']} ---\")\n",
    "    \n",
    "    cmd = [\n",
    "        \"python\", \"train.py\",\n",
    "        \"--dataset\", fixed_params[\"dataset\"],\n",
    "        \"--num_sa\", fixed_params[\"num_sa\"],\n",
    "        \"--num_gnns\", fixed_params[\"num_gnns\"],\n",
    "        \"--hidden\", fixed_params[\"hidden\"],\n",
    "        \"--alpha\", fixed_params[\"alpha\"],\n",
    "        \"--lr\", fixed_params[\"lr\"],\n",
    "        \"--lr_sa\", fixed_params[\"lr_sa\"],\n",
    "        \"--weight_decay\", str(config[\"wd\"]),\n",
    "        \"--weight_decay_sa\", str(config[\"wd\"]),\n",
    "        \"--dropout\", str(config[\"dropout\"]),\n",
    "        \"--dropout_sa\", str(config[\"dropout\"]),\n",
    "        \"--num_heads\", str(config[\"heads\"]),\n",
    "        \"--epochs\", fixed_params[\"epochs\"],\n",
    "        \"--runs\", fixed_params[\"runs\"],\n",
    "        \"--patience\", fixed_params[\"patience\"]\n",
    "    ]\n",
    "    \n",
    "    # Chạy lệnh và lấy kết quả từ log\n",
    "    process = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    output = process.stdout\n",
    "    \n",
    "    # Tìm dòng chứa kết quả ACC cuối cùng\n",
    "    try:\n",
    "        acc_line = [line for line in output.split('\\n') if \"ACC, mean\" in line][-1]\n",
    "        current_acc = float(acc_line.split(':')[1].split('%')[0].strip())\n",
    "        print(f\">> Kết quả trung bình: {current_acc}%\")\n",
    "        \n",
    "        if current_acc > best_acc:\n",
    "            best_acc = current_acc\n",
    "            best_config = \" \".join(cmd[2:]) # Lưu lại các tham số để có thể chạy lại\n",
    "    except:\n",
    "        print(\"Lỗi khi đọc kết quả từ log.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"KẾT QUẢ CAO NHẤT: {best_acc}%\")\n",
    "print(f\"Lệnh chạy bộ tham số này:\\npython train.py {best_config} --runs 10\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T02:47:40.565695Z",
     "iopub.status.busy": "2026-01-06T02:47:40.565133Z",
     "iopub.status.idle": "2026-01-06T02:48:54.074039Z",
     "shell.execute_reply": "2026-01-06T02:48:54.073292Z",
     "shell.execute_reply.started": "2026-01-06T02:47:40.565666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: cora\n",
      "(T):  42%|█▋  | 126/300 [00:06<00:09, 18.22it/s, Train Loss=0.245, Val Loss=0.8]\n",
      "1-th run, micro-f1:83.50%, macor-f1:82.08%; acc:83.50%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:08, 19.59it/s, Train Loss=0.245, Val Loss=0.801]\n",
      "2-th run, micro-f1:83.40%, macor-f1:81.99%; acc:83.40%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:08, 19.44it/s, Train Loss=0.245, Val Loss=0.797]\n",
      "3-th run, micro-f1:83.60%, macor-f1:82.15%; acc:83.60%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:08, 19.38it/s, Train Loss=0.245, Val Loss=0.796]\n",
      "4-th run, micro-f1:83.50%, macor-f1:82.09%; acc:83.50%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:08, 19.36it/s, Train Loss=0.246, Val Loss=0.799]\n",
      "5-th run, micro-f1:83.60%, macor-f1:82.26%; acc:83.60%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:09, 19.17it/s, Train Loss=0.248, Val Loss=0.796]\n",
      "6-th run, micro-f1:83.40%, macor-f1:82.01%; acc:83.40%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:09, 19.07it/s, Train Loss=0.247, Val Loss=0.797]\n",
      "7-th run, micro-f1:83.50%, macor-f1:82.09%; acc:83.50%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:09, 18.90it/s, Train Loss=0.241, Val Loss=0.801]\n",
      "8-th run, micro-f1:83.60%, macor-f1:82.25%; acc:83.60%;\n",
      "(T):  42%|▊ | 126/300 [00:06<00:09, 18.86it/s, Train Loss=0.245, Val Loss=0.799]\n",
      "9-th run, micro-f1:83.40%, macor-f1:82.00%; acc:83.40%;\n",
      "(T):  42%|█▋  | 126/300 [00:06<00:09, 18.69it/s, Train Loss=0.242, Val Loss=0.8]\n",
      "10-th run, micro-f1:83.60%, macor-f1:82.15%; acc:83.60%;\n",
      "After 10 runs on  cora !\n",
      "Micro-F1, mean ± std: 83.51%±0.08\n",
      "Macro-F1, mean ± std: 82.11%±0.09\n",
      "ACC, mean ± std: 83.51%±0.08\n",
      "Saving results to the'results/sgc_cora.csv'\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset cora --num_sa 3 --num_gnns 2 --hidden 256 --alpha 0.1 --lr 0.001 --lr_sa 0.001 --weight_decay 0.0001 --weight_decay_sa 0.0001 --dropout 0.5 --dropout_sa 0.5 --num_heads 4 --epochs 300 --runs 5 --patience 50 --runs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T02:45:29.496528Z",
     "iopub.status.busy": "2026-01-06T02:45:29.496236Z",
     "iopub.status.idle": "2026-01-06T02:45:29.808513Z",
     "shell.execute_reply": "2026-01-06T02:45:29.807853Z",
     "shell.execute_reply.started": "2026-01-06T02:45:29.496504Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy các file kết quả: ['results/sgc_cora.csv']\n",
      "                 0                1                2          3           4   \\\n",
      "0   mi:82.60 ± 0.00  ma:80.81 ± 0.00  ma:82.60 ± 0.00  seed:2024  epochs:200   \n",
      "1   mi:80.52 ± 0.11  ma:79.20 ± 0.14  ma:80.52 ± 0.11  seed:2024  epochs:300   \n",
      "2   mi:82.80 ± 0.00  ma:82.41 ± 0.00  ma:82.80 ± 0.00  seed:2024  epochs:200   \n",
      "3   mi:79.96 ± 0.05  ma:78.31 ± 0.03  ma:79.96 ± 0.05  seed:2024  epochs:200   \n",
      "4   mi:79.90 ± 0.00  ma:80.06 ± 0.00  ma:79.90 ± 0.00  seed:2024  epochs:200   \n",
      "5   mi:79.10 ± 0.00  ma:77.13 ± 0.00  ma:79.10 ± 0.00  seed:2024  epochs:200   \n",
      "6   mi:82.72 ± 0.09  ma:81.54 ± 0.08  ma:82.72 ± 0.09  seed:2024  epochs:300   \n",
      "7   mi:82.33 ± 0.15  ma:81.31 ± 0.13  ma:82.33 ± 0.15  seed:2024  epochs:300   \n",
      "8   mi:82.34 ± 0.14  ma:81.23 ± 0.10  ma:82.34 ± 0.14  seed:2024  epochs:300   \n",
      "9   mi:80.20 ± 0.00  ma:79.50 ± 0.00  ma:80.20 ± 0.00  seed:2024  epochs:300   \n",
      "10  mi:80.80 ± 0.00  ma:80.37 ± 0.00  ma:80.80 ± 0.00  seed:2024  epochs:300   \n",
      "11  mi:81.50 ± 0.00  ma:80.52 ± 0.00  ma:81.50 ± 0.00  seed:2024  epochs:300   \n",
      "12  mi:82.20 ± 0.00  ma:81.26 ± 0.00  ma:82.20 ± 0.00  seed:2024  epochs:300   \n",
      "13  mi:82.84 ± 0.08  ma:81.73 ± 0.11  ma:82.84 ± 0.08  seed:2024  epochs:300   \n",
      "14  mi:82.24 ± 0.05  ma:81.16 ± 0.03  ma:82.24 ± 0.05  seed:2024  epochs:300   \n",
      "15  mi:80.40 ± 0.00  ma:79.77 ± 0.00  ma:80.40 ± 0.00  seed:2024  epochs:300   \n",
      "16  mi:81.06 ± 0.08  ma:80.64 ± 0.06  ma:81.06 ± 0.08  seed:2024  epochs:300   \n",
      "17  mi:81.30 ± 0.00  ma:80.33 ± 0.00  ma:81.30 ± 0.00  seed:2024  epochs:300   \n",
      "18  mi:81.96 ± 0.05  ma:80.96 ± 0.07  ma:81.96 ± 0.05  seed:2024  epochs:300   \n",
      "19  mi:82.26 ± 0.10  ma:81.26 ± 0.07  ma:82.26 ± 0.10  seed:2024  epochs:300   \n",
      "20  mi:83.40 ± 0.09  ma:82.02 ± 0.09  ma:83.40 ± 0.09  seed:2024  epochs:300   \n",
      "21  mi:80.86 ± 0.10  ma:80.18 ± 0.09  ma:80.86 ± 0.10  seed:2024  epochs:300   \n",
      "22  mi:80.74 ± 0.05  ma:80.26 ± 0.07  ma:80.74 ± 0.05  seed:2024  epochs:300   \n",
      "23  mi:81.40 ± 0.09  ma:80.50 ± 0.10  ma:81.40 ± 0.09  seed:2024  epochs:300   \n",
      "24  mi:81.68 ± 0.04  ma:80.78 ± 0.04  ma:81.68 ± 0.04  seed:2024  epochs:300   \n",
      "25  mi:82.32 ± 0.18  ma:81.30 ± 0.20  ma:82.32 ± 0.18  seed:2024  epochs:300   \n",
      "26  mi:83.08 ± 0.12  ma:81.80 ± 0.13  ma:83.08 ± 0.12  seed:2024  epochs:300   \n",
      "\n",
      "             5         6          7               8                9   ...  \\\n",
      "0   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "1   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "2   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "3   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "4   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "5   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "6   patience:50  lr:0.001  wd:0.0005  lr_trans:0.001  wd_trans:0.0005  ...   \n",
      "7   patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "8   patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "9   patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "10  patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "11  patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "12  patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "13  patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "14  patience:50  lr:0.001   wd:0.001  lr_trans:0.001   wd_trans:0.001  ...   \n",
      "15  patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "16  patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "17  patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "18  patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "19  patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "20  patience:50  lr:0.001  wd:0.0001  lr_trans:0.001  wd_trans:0.0001  ...   \n",
      "21  patience:50  lr:0.001   wd:1e-05  lr_trans:0.001   wd_trans:1e-05  ...   \n",
      "22  patience:50  lr:0.001   wd:1e-05  lr_trans:0.001   wd_trans:1e-05  ...   \n",
      "23  patience:50  lr:0.001   wd:1e-05  lr_trans:0.001   wd_trans:1e-05  ...   \n",
      "24  patience:50  lr:0.001   wd:1e-05  lr_trans:0.001   wd_trans:1e-05  ...   \n",
      "25  patience:50  lr:0.001   wd:1e-05  lr_trans:0.001   wd_trans:1e-05  ...   \n",
      "26  patience:50  lr:0.001   wd:1e-05  lr_trans:0.001   wd_trans:1e-05  ...   \n",
      "\n",
      "            11          12        13           14           15  \\\n",
      "0   hidden:256  num_gnns:2  num_sa:1  num_heads:4  dropout:0.5   \n",
      "1   hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.5   \n",
      "2   hidden:256  num_gnns:2  num_sa:1  num_heads:4  dropout:0.5   \n",
      "3   hidden:256  num_gnns:2  num_sa:1  num_heads:4  dropout:0.5   \n",
      "4   hidden:256  num_gnns:2  num_sa:1  num_heads:4  dropout:0.5   \n",
      "5   hidden:256  num_gnns:2  num_sa:1  num_heads:4  dropout:0.5   \n",
      "6   hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.5   \n",
      "7   hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.5   \n",
      "8   hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.5   \n",
      "9   hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.1   \n",
      "10  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.1   \n",
      "11  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.3   \n",
      "12  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.3   \n",
      "13  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.5   \n",
      "14  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.5   \n",
      "15  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.1   \n",
      "16  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.1   \n",
      "17  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.3   \n",
      "18  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.3   \n",
      "19  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.5   \n",
      "20  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.5   \n",
      "21  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.1   \n",
      "22  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.1   \n",
      "23  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.3   \n",
      "24  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.3   \n",
      "25  hidden:256  num_gnns:2  num_sa:3  num_heads:2  dropout:0.5   \n",
      "26  hidden:256  num_gnns:2  num_sa:3  num_heads:4  dropout:0.5   \n",
      "\n",
      "                16         17          18           19       20  \n",
      "0   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:1  \n",
      "1   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True  runs:10  \n",
      "2   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:1  \n",
      "3   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True  runs:10  \n",
      "4   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:1  \n",
      "5   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:1  \n",
      "6   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True  runs:10  \n",
      "7   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True  runs:10  \n",
      "8   dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True  runs:10  \n",
      "9   dropout_sa:0.1  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "10  dropout_sa:0.1  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "11  dropout_sa:0.3  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "12  dropout_sa:0.3  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "13  dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "14  dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "15  dropout_sa:0.1  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "16  dropout_sa:0.1  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "17  dropout_sa:0.3  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "18  dropout_sa:0.3  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "19  dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "20  dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "21  dropout_sa:0.1  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "22  dropout_sa:0.1  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "23  dropout_sa:0.3  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "24  dropout_sa:0.3  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "25  dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "26  dropout_sa:0.5  alpha:0.1  lammda:0.1  use_bn:True   runs:5  \n",
      "\n",
      "[27 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Tìm file kết quả vừa sinh ra\n",
    "result_files = glob.glob('results/*.csv')\n",
    "\n",
    "if result_files:\n",
    "    print(\"Tìm thấy các file kết quả:\", result_files)\n",
    "    # Đọc file mới nhất\n",
    "    df = pd.read_csv(result_files[0], header=None)\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Chưa thấy file kết quả nào.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
